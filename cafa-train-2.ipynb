{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33a2860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:14:54.525190Z",
     "iopub.status.busy": "2023-07-04T08:14:54.524740Z",
     "iopub.status.idle": "2023-07-04T08:15:25.296519Z",
     "shell.execute_reply": "2023-07-04T08:15:25.295384Z"
    },
    "papermill": {
     "duration": 30.783203,
     "end_time": "2023-07-04T08:15:25.299068",
     "exception": false,
     "start_time": "2023-07-04T08:14:54.515865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-optimizer\r\n",
      "  Downloading pytorch_optimizer-2.11.0-py3-none-any.whl (150 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch-optimizer) (1.23.5)\r\n",
      "Requirement already satisfied: torch>=1.10 in /opt/conda/lib/python3.10/site-packages (from pytorch-optimizer) (2.0.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->pytorch-optimizer) (3.12.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->pytorch-optimizer) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->pytorch-optimizer) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->pytorch-optimizer) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10->pytorch-optimizer) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10->pytorch-optimizer) (2.1.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10->pytorch-optimizer) (1.3.0)\r\n",
      "Installing collected packages: pytorch-optimizer\r\n",
      "Successfully installed pytorch-optimizer-2.11.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting anc2vec@ git+https://github.com/aedera/anc2vec.git\r\n",
      "  Cloning https://github.com/aedera/anc2vec.git to /tmp/pip-install-hfje3eq1/anc2vec_5e5c935ce0c54fc88c3e9892b5f74a5b\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/aedera/anc2vec.git /tmp/pip-install-hfje3eq1/anc2vec_5e5c935ce0c54fc88c3e9892b5f74a5b\r\n",
      "  Resolved https://github.com/aedera/anc2vec.git to commit d828ad7ce9606e98cd349a5c48d6fc825edcf4c1\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\r\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of anc2vec to determine which version is compatible with other requirements. This could take a while.\r\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow<2.5,>=2.3.1 (from anc2vec) (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow<2.5,>=2.3.1\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -U pytorch-optimizer\n",
    "!pip install -U \"anc2vec @ git+https://github.com/aedera/anc2vec.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b1ca56",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-04T08:15:25.317198Z",
     "iopub.status.busy": "2023-07-04T08:15:25.316860Z",
     "iopub.status.idle": "2023-07-04T08:15:38.498598Z",
     "shell.execute_reply": "2023-07-04T08:15:38.497662Z"
    },
    "papermill": {
     "duration": 13.193502,
     "end_time": "2023-07-04T08:15:38.501002",
     "exception": false,
     "start_time": "2023-07-04T08:15:25.307500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "from pytorch_optimizer import Ranger, SoftF1Loss\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3dea040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:15:38.518970Z",
     "iopub.status.busy": "2023-07-04T08:15:38.518676Z",
     "iopub.status.idle": "2023-07-04T08:15:38.585924Z",
     "shell.execute_reply": "2023-07-04T08:15:38.584941Z"
    },
    "papermill": {
     "duration": 0.078513,
     "end_time": "2023-07-04T08:15:38.587947",
     "exception": false,
     "start_time": "2023-07-04T08:15:38.509434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = {\"root_data\": '/kaggle/input/cafa-5-protein-function-prediction',\n",
    "          \"root_embed\": '/kaggle/input/23468234',\n",
    "          \"exp_name\": 'all, 600 label, 250 iter, sigmoid cosine, seed : 42',\n",
    "          \"n_labels\": 600,\n",
    "          \"seeds\": [42],\n",
    "          \"min_ia\": 1,\n",
    "          \"epoch\": 250,\n",
    "          \"lr\": 1e-3,\n",
    "          \"batch_size\": 256,\n",
    "          \"n_accumulate\": 1,\n",
    "          \"loss\": 'cce', # 'cce', 'sigmoidf1' 'softf1'\n",
    "          \"scheduler\": 'cosine', # 'cosine', 'onecycle'\n",
    "          \"device\": torch.device('cuda' if torch.cuda.is_available() else 'cpu')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31305bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:15:38.605664Z",
     "iopub.status.busy": "2023-07-04T08:15:38.605373Z",
     "iopub.status.idle": "2023-07-04T08:15:38.610634Z",
     "shell.execute_reply": "2023-07-04T08:15:38.609770Z"
    },
    "papermill": {
     "duration": 0.016548,
     "end_time": "2023-07-04T08:15:38.612817",
     "exception": false,
     "start_time": "2023-07-04T08:15:38.596269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Experiment: \n",
      "all, 600 label, 250 iter, sigmoid cosine, seed : 42\n"
     ]
    }
   ],
   "source": [
    "print(\"## Experiment: \")\n",
    "print(CONFIG['exp_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a01ea14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:15:38.630576Z",
     "iopub.status.busy": "2023-07-04T08:15:38.629974Z",
     "iopub.status.idle": "2023-07-04T08:15:38.635478Z",
     "shell.execute_reply": "2023-07-04T08:15:38.634477Z"
    },
    "papermill": {
     "duration": 0.016819,
     "end_time": "2023-07-04T08:15:38.637781",
     "exception": false,
     "start_time": "2023-07-04T08:15:38.620962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5a471",
   "metadata": {
    "papermill": {
     "duration": 0.008148,
     "end_time": "2023-07-04T08:15:38.654032",
     "exception": false,
     "start_time": "2023-07-04T08:15:38.645884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get Train Terms & Load Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "679fe7e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:15:38.671369Z",
     "iopub.status.busy": "2023-07-04T08:15:38.671078Z",
     "iopub.status.idle": "2023-07-04T08:15:41.825941Z",
     "shell.execute_reply": "2023-07-04T08:15:41.824802Z"
    },
    "papermill": {
     "duration": 3.166525,
     "end_time": "2023-07-04T08:15:41.828654",
     "exception": false,
     "start_time": "2023-07-04T08:15:38.662129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(CONFIG[\"root_data\"], 'Train', 'train_terms.tsv'), sep='\\t')\n",
    "IA = pd.read_csv(os.path.join(CONFIG[\"root_data\"], 'IA.txt'), sep='\\t', header=None, names=[\"term\", \"val\"])\n",
    "IA = IA[IA[\"val\"] > CONFIG[\"min_ia\"]].reset_index().drop([\"index\"], axis=1)\n",
    "IA = IA[\"term\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04e3585",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:15:41.850661Z",
     "iopub.status.busy": "2023-07-04T08:15:41.850344Z",
     "iopub.status.idle": "2023-07-04T08:17:08.592019Z",
     "shell.execute_reply": "2023-07-04T08:17:08.591047Z"
    },
    "papermill": {
     "duration": 86.754765,
     "end_time": "2023-07-04T08:17:08.594656",
     "exception": false,
     "start_time": "2023-07-04T08:15:41.839891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142246/142246 [01:17<00:00, 1827.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 1.]]\n",
      "(142246, 600)\n"
     ]
    }
   ],
   "source": [
    "ids = np.load('/kaggle/input/4637427/train_ids_esm2_t36_3B_UR50D.npy')\n",
    "labels = train_data\n",
    "\n",
    "top_terms = labels.groupby(\"term\")[\"EntryID\"].count().sort_values(ascending=False)\n",
    "labels_names = top_terms[:CONFIG[\"n_labels\"]].index.values\n",
    "train_labels_sub = labels[(labels.term.isin(labels_names)) & (labels.EntryID.isin(ids))]\n",
    "id_labels = train_labels_sub.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "go_terms_map = {label: i for i, label in enumerate(labels_names)}\n",
    "labels_matrix = np.empty((len(ids), len(labels_names)))\n",
    "\n",
    "for index, id in tqdm(enumerate(ids), total=len(ids)):\n",
    "    id_gos_list = id_labels[id]\n",
    "    temp = [go_terms_map[go] for go in labels_names if go in id_gos_list]\n",
    "    labels_matrix[index, temp] = 1\n",
    "    \n",
    "print(labels_matrix)\n",
    "print(labels_matrix.shape)\n",
    "\n",
    "np.save(\"/kaggle/working/train_targets_top\"+str(CONFIG[\"n_labels\"])+\".npy\", np.array(labels_matrix))\n",
    "\n",
    "del labels_matrix\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5ede6",
   "metadata": {
    "papermill": {
     "duration": 0.06346,
     "end_time": "2023-07-04T08:17:08.721037",
     "exception": false,
     "start_time": "2023-07-04T08:17:08.657577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b8df9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:17:08.848268Z",
     "iopub.status.busy": "2023-07-04T08:17:08.847891Z",
     "iopub.status.idle": "2023-07-04T08:17:08.859722Z",
     "shell.execute_reply": "2023-07-04T08:17:08.858800Z"
    },
    "papermill": {
     "duration": 0.077649,
     "end_time": "2023-07-04T08:17:08.861831",
     "exception": false,
     "start_time": "2023-07-04T08:17:08.784182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, ids_source, embedding_source1, embedding_source2, target_source, train=True):\n",
    "        ids = np.load(ids_source)\n",
    "        if embedding_source2 is not None:\n",
    "            embeds1 = np.load(embedding_source1)\n",
    "            embeds2 = np.load(embedding_source2)\n",
    "            embeds = np.concatenate((embeds1, embeds2), axis=1)\n",
    "\n",
    "            del embeds1, embeds2\n",
    "            gc.collect()\n",
    "            \n",
    "            print(embeds.shape)\n",
    "        \n",
    "        else:\n",
    "            embeds = np.load(embedding_source1)\n",
    "        \n",
    "        self.train = train\n",
    "        \n",
    "        embeds_list = []\n",
    "        for l in range(embeds.shape[0]):\n",
    "            embeds_list.append(embeds[l,:])\n",
    "            \n",
    "        self.df = pd.DataFrame(data={\"EntryID\": ids, \"embed\" : embeds_list})\n",
    "        \n",
    "        if self.train:\n",
    "            target = np.load(target_source)\n",
    "            df_labels = pd.DataFrame({\"EntryID\": ids, \"target\": target.tolist()})\n",
    "            del target\n",
    "            gc.collect()\n",
    "            self.df = self.df.merge(df_labels, on=\"EntryID\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        embed = torch.tensor(self.df.iloc[index][\"embed\"] , dtype = torch.float32)\n",
    "        if self.train:\n",
    "            target = torch.tensor(self.df.iloc[index][\"target\"], dtype = torch.float32)\n",
    "            return {\n",
    "                'embed': embed,\n",
    "                'target': target,\n",
    "            }\n",
    "        else:\n",
    "            id = self.df.iloc[index][\"EntryID\"]\n",
    "            return { \n",
    "                'embed': embed,\n",
    "                'id' : id\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7d480",
   "metadata": {
    "papermill": {
     "duration": 0.066091,
     "end_time": "2023-07-04T08:17:08.989885",
     "exception": false,
     "start_time": "2023-07-04T08:17:08.923794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b7d2b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:17:09.131534Z",
     "iopub.status.busy": "2023-07-04T08:17:09.131162Z",
     "iopub.status.idle": "2023-07-04T08:17:09.146216Z",
     "shell.execute_reply": "2023-07-04T08:17:09.145060Z"
    },
    "papermill": {
     "duration": 0.093728,
     "end_time": "2023-07-04T08:17:09.148540",
     "exception": false,
     "start_time": "2023-07-04T08:17:09.054812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size1, hidden_size2, target_size, dropout=0.8, num_emb_layers=2):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.input_block = nn.Sequential(nn.LayerNorm(embed_size, eps=1e-6),\n",
    "                                         nn.Linear(embed_size, hidden_size1), \n",
    "                                         nn.LeakyReLU())\n",
    "\n",
    "        self.hidden_block1 = []\n",
    "        for i in range(num_emb_layers - 1):\n",
    "            self.hidden_block1.extend([nn.LayerNorm(hidden_size1, eps=1e-6), \n",
    "                                       nn.Dropout(0.15), \n",
    "                                       nn.Linear(hidden_size1, hidden_size1), \n",
    "                                       nn.LeakyReLU()])\n",
    "            \n",
    "            if i == num_emb_layers - 2:\n",
    "                self.hidden_block1.extend([nn.LayerNorm(hidden_size1, eps=1e-6)])\n",
    "        self.hidden_block1.extend([nn.LayerNorm(hidden_size1, eps=1e-6), \n",
    "                                   nn.Dropout(0.15), \n",
    "                                   nn.Linear(hidden_size1, hidden_size2)])\n",
    "        self.hidden_block1 = nn.Sequential(*self.hidden_block1)\n",
    "        \n",
    "        self.hidden_block2 = []\n",
    "        for i in range(num_emb_layers - 1):\n",
    "            self.hidden_block2.extend([nn.LayerNorm(hidden_size2, eps=1e-6), \n",
    "                                       nn.Dropout(0.15), \n",
    "                                       nn.Linear(hidden_size2, hidden_size2), \n",
    "                                       nn.LeakyReLU()])\n",
    "            \n",
    "            if i == num_emb_layers - 2:\n",
    "                self.hidden_block2.extend([nn.LayerNorm(hidden_size2, eps=1e-6)])\n",
    "        self.hidden_block2 = nn.Sequential(*self.hidden_block2)\n",
    "        \n",
    "        self.output_block = nn.Sequential(nn.LayerNorm(hidden_size2, eps=1e-6), \n",
    "                                          nn.Dropout(0.15), \n",
    "                                          nn.Linear(hidden_size2, target_size))\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        out = self.input_block(x)\n",
    "        out = self.dropout(self.hidden_block1(out))\n",
    "        out = self.dropout(self.hidden_block2(out))\n",
    "        out = self.output_block(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48b719de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:17:09.293855Z",
     "iopub.status.busy": "2023-07-04T08:17:09.293531Z",
     "iopub.status.idle": "2023-07-04T08:17:09.302048Z",
     "shell.execute_reply": "2023-07-04T08:17:09.301131Z"
    },
    "papermill": {
     "duration": 0.081781,
     "end_time": "2023-07-04T08:17:09.304031",
     "exception": false,
     "start_time": "2023-07-04T08:17:09.222250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/gabriben/metrics-as-losses\n",
    "class sigmoidF1(nn.Module):\n",
    "\n",
    "    def __init__(self, S = -1, E = 0):\n",
    "        super(sigmoidF1, self).__init__()\n",
    "        self.S = S\n",
    "        self.E = E\n",
    "\n",
    "    @torch.cuda.amp.autocast()\n",
    "    def forward(self, y_hat, y):\n",
    "        \n",
    "        y_hat = torch.sigmoid(y_hat)\n",
    "\n",
    "        b = torch.tensor(self.S)\n",
    "        c = torch.tensor(self.E)\n",
    "\n",
    "        sig = 1 / (1 + torch.exp(b * (y_hat + c)))\n",
    "\n",
    "        tp = torch.sum(sig * y, dim=0)\n",
    "        fp = torch.sum(sig * (1 - y), dim=0)\n",
    "        fn = torch.sum((1 - sig) * y, dim=0)\n",
    "\n",
    "        sigmoid_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "        cost = 1 - sigmoid_f1\n",
    "        macroCost = torch.mean(cost)\n",
    "\n",
    "        return macroCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "083b9889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:17:09.432622Z",
     "iopub.status.busy": "2023-07-04T08:17:09.431645Z",
     "iopub.status.idle": "2023-07-04T08:17:09.438630Z",
     "shell.execute_reply": "2023-07-04T08:17:09.437605Z"
    },
    "papermill": {
     "duration": 0.074653,
     "end_time": "2023-07-04T08:17:09.440886",
     "exception": false,
     "start_time": "2023-07-04T08:17:09.366233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def criterion(output, target):\n",
    "    if CONFIG['loss'] == \"softf1\":\n",
    "        loss = SoftF1Loss()\n",
    "    elif CONFIG['loss'] == \"cce\":\n",
    "        loss = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    elif CONFIG['loss'] == \"sigmoidf1\":\n",
    "        loss = sigmoidF1()\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return loss(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad4c1cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:17:09.573242Z",
     "iopub.status.busy": "2023-07-04T08:17:09.572871Z",
     "iopub.status.idle": "2023-07-04T08:17:09.578004Z",
     "shell.execute_reply": "2023-07-04T08:17:09.577044Z"
    },
    "papermill": {
     "duration": 0.071451,
     "end_time": "2023-07-04T08:17:09.580006",
     "exception": false,
     "start_time": "2023-07-04T08:17:09.508555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1score(output, target):\n",
    "    score = MultilabelF1Score(num_labels=CONFIG['n_labels']).to(CONFIG['device'])\n",
    "    return score(output, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552eecae",
   "metadata": {
    "papermill": {
     "duration": 0.065383,
     "end_time": "2023-07-04T08:17:09.707633",
     "exception": false,
     "start_time": "2023-07-04T08:17:09.642250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22ad27d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:17:09.838738Z",
     "iopub.status.busy": "2023-07-04T08:17:09.837607Z",
     "iopub.status.idle": "2023-07-04T08:17:09.847615Z",
     "shell.execute_reply": "2023-07-04T08:17:09.846655Z"
    },
    "papermill": {
     "duration": 0.077206,
     "end_time": "2023-07-04T08:17:09.849624",
     "exception": false,
     "start_time": "2023-07-04T08:17:09.772418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, epoch, verbose):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_score = 0.0\n",
    "    \n",
    "    #bar = tqdm(enumerate(dataloader), total=len(dataloader), leave=verbose)\n",
    "    for step, data in enumerate(dataloader):\n",
    "        embeds = data['embed'].to(CONFIG['device'])\n",
    "        targets = data['target'].to(CONFIG['device'])\n",
    "        batch_size = embeds.size(0)\n",
    "        \n",
    "        preds = model(embeds)\n",
    "        \n",
    "        score = f1score(preds, targets)\n",
    "        loss = criterion(preds, targets)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if scheduler is not None:\n",
    "                scheduler.step(epoch_loss)\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_score += (score.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_score = running_score / dataset_size\n",
    "        \n",
    "#     bar.set_postfix(Epoch=epoch, \n",
    "#                     Train_Loss=epoch_loss,\n",
    "#                     LR=optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "    # garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e84e867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:17:09.980672Z",
     "iopub.status.busy": "2023-07-04T08:17:09.980330Z",
     "iopub.status.idle": "2023-07-04T08:17:09.988430Z",
     "shell.execute_reply": "2023-07-04T08:17:09.987405Z"
    },
    "papermill": {
     "duration": 0.078484,
     "end_time": "2023-07-04T08:17:09.991392",
     "exception": false,
     "start_time": "2023-07-04T08:17:09.912908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "\n",
    "def valid_one_epoch(model, optimizer, dataloader, scheduler, epoch, verbose):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_score = 0.0\n",
    "    \n",
    "    #bar = tqdm(enumerate(dataloader), total=len(dataloader), leave=verbose)\n",
    "    for step, data in enumerate(dataloader):        \n",
    "        embeds = data['embed'].to(CONFIG['device'])\n",
    "        targets = data['target'].to(CONFIG['device'])\n",
    "        batch_size = embeds.size(0)\n",
    "        \n",
    "        preds = model(embeds)\n",
    "        \n",
    "        score = f1score(preds, targets)\n",
    "        loss = criterion(preds, targets)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_score += (score.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_score = running_score / dataset_size\n",
    "        \n",
    "#     bar.set_postfix(Epoch=epoch, \n",
    "#                     Valid_Loss=epoch_loss,\n",
    "#                     LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "472dffef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:17:10.119651Z",
     "iopub.status.busy": "2023-07-04T08:17:10.119293Z",
     "iopub.status.idle": "2023-07-04T08:17:10.132476Z",
     "shell.execute_reply": "2023-07-04T08:17:10.130903Z"
    },
    "papermill": {
     "duration": 0.079995,
     "end_time": "2023-07-04T08:17:10.134510",
     "exception": false,
     "start_time": "2023-07-04T08:17:10.054515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, train_loader, val_loader, num_epochs, verbose=True):\n",
    "    train_score = []\n",
    "    val_score = []\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_score = 0.0                                                                                             \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            \n",
    "        gc.collect()\n",
    "        train_epoch_loss, train_epoch_score = train_one_epoch(model=model, \n",
    "                                                              optimizer=optimizer, \n",
    "                                                              scheduler=scheduler, \n",
    "                                                              dataloader=train_loader,  \n",
    "                                                              epoch=epoch,\n",
    "                                                              verbose=verbose)\n",
    "        train_score.append(train_epoch_score)\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        \n",
    "        if val_loader is not None:                                                                      \n",
    "            val_epoch_loss, val_epoch_score = valid_one_epoch(model=model, \n",
    "                                                              optimizer=optimizer,\n",
    "                                                              dataloader=val_loader, \n",
    "                                                              scheduler=scheduler,\n",
    "                                                              epoch=epoch,\n",
    "                                                              verbose=verbose)\n",
    "\n",
    "            val_score.append(val_epoch_score)\n",
    "            val_loss.append(val_epoch_loss)\n",
    "            if verbose:\n",
    "                print(f\"Train loss: {train_epoch_loss} Validation loss: {val_epoch_loss}\")\n",
    "                print(f\"Train score: {train_epoch_score} Validation score: {val_epoch_score}\")\n",
    "\n",
    "            if val_epoch_score >= best_epoch_score:\n",
    "                if verbose:\n",
    "                    print(f\"Validation Loss Improved ({best_epoch_score} ---> {val_epoch_loss})\")\n",
    "\n",
    "                best_epoch_loss = val_epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            print()\n",
    "        \n",
    "        else:\n",
    "            val_score = None\n",
    "            val_loss = None\n",
    "            if verbose:\n",
    "                print(f\"Train loss: {train_epoch_loss}\")\n",
    "                print(f\"Train score: {train_epoch_score}\")\n",
    "            \n",
    "            if train_epoch_score >= best_epoch_score:\n",
    "                if verbose:\n",
    "                    print(f\"Score Improved ({best_epoch_score} ---> {train_epoch_score})\")\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                                                                                                  \n",
    "        end = time.time()\n",
    "                                                                                                  \n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    \n",
    "    print(\"Best Score: {:.4f}\".format(best_epoch_score))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_score, train_loss, val_score, val_loss                                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d46494",
   "metadata": {
    "papermill": {
     "duration": 0.06204,
     "end_time": "2023-07-04T08:17:10.258765",
     "exception": false,
     "start_time": "2023-07-04T08:17:10.196725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88f06878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:17:10.384412Z",
     "iopub.status.busy": "2023-07-04T08:17:10.384060Z",
     "iopub.status.idle": "2023-07-04T08:17:10.398995Z",
     "shell.execute_reply": "2023-07-04T08:17:10.398046Z"
    },
    "papermill": {
     "duration": 0.080484,
     "end_time": "2023-07-04T08:17:10.401065",
     "exception": false,
     "start_time": "2023-07-04T08:17:10.320581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_folds(folds, data='all', save_output=True):\n",
    "    num_labels = CONFIG['n_labels']\n",
    "    \n",
    "    print(\"## Loading Dataset\")\n",
    "    dataset = ProteinDataset(ids_source='/kaggle/input/4637427/train_ids_esm2_t36_3B_UR50D.npy',\n",
    "                             embedding_source1='/kaggle/input/23468234/train_embeds_esm2_t33_650M_UR50D.npy',\n",
    "                             embedding_source2='/kaggle/input/t5embeds/train_embeds.npy',\n",
    "                             target_source=f\"/kaggle/working/train_targets_top{num_labels}.npy\",\n",
    "                             train=True)\n",
    "    train_losses = []\n",
    "    train_scores = []\n",
    "    val_losses = []\n",
    "    val_scores = []\n",
    "    \n",
    "    print(\"## Running Training\")\n",
    "    \n",
    "    for seed in folds:\n",
    "        set_seed(seed)\n",
    "        print(\"#### Seed: \", seed, \"####\")\n",
    "        print()\n",
    "        if data != 'all':\n",
    "            generator = torch.Generator().manual_seed(seed)\n",
    "            train_dataset, val_dataset = random_split(dataset, \n",
    "                                                      lengths = [int(len(dataset)*0.9), \n",
    "                                                                 len(dataset)-int(len(dataset)*0.9)],\n",
    "                                                      generator=generator)\n",
    "\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=CONFIG['batch_size'], num_workers=2, shuffle=True)\n",
    "            val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=CONFIG['batch_size'], num_workers=2, shuffle=False)\n",
    "            \n",
    "        else:\n",
    "            train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=CONFIG['batch_size'], num_workers=2, shuffle=True)\n",
    "            val_dataloader = None\n",
    "            \n",
    "        model = LinearModel(embed_size=2304, \n",
    "                            hidden_size1=1912,\n",
    "                            hidden_size2=1024,\n",
    "                            target_size=CONFIG['n_labels'], \n",
    "                            dropout=0.8, \n",
    "                            num_emb_layers=3).to(CONFIG['device'])\n",
    "\n",
    "        optimizer = Ranger(model.parameters(), lr=CONFIG['lr']) \n",
    "        \n",
    "        if CONFIG['scheduler'] == 'cosine':\n",
    "            scheduler = CosineAnnealingLR(optimizer, (CONFIG['epoch'] * 501))\n",
    "        elif CONFIG['scheduler'] == 'onecycle':\n",
    "            scheduler = OneCycleLR(optimizer, max_lr=CONFIG['lr'], total_steps=CONFIG['epoch'] * 501)\n",
    "\n",
    "        model, train_score, train_loss, val_score, val_loss = run_training(model=model, \n",
    "                                                                           optimizer=optimizer, \n",
    "                                                                           scheduler=None, \n",
    "                                                                           train_loader=train_dataloader, \n",
    "                                                                           val_loader=val_dataloader,\n",
    "                                                                           num_epochs=CONFIG['epoch'], \n",
    "                                                                           verbose=True)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_scores.append(train_score)\n",
    "        val_losses.append(val_loss)\n",
    "        val_scores.append(val_score)\n",
    "        \n",
    "        if save_output:\n",
    "            root_save = \"/kaggle/working/\"\n",
    "            os.makedirs(os.path.dirname(f\"{root_save}/model_{seed}.pt\"), exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"{root_save}/model_{seed}.pt\")\n",
    "        \n",
    "        del model, train_dataloader, val_dataloader, train_score, train_loss, val_score, val_loss\n",
    "        _ = gc.collect()\n",
    "        \n",
    "    return train_losses, train_scores, val_losses, val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c1f05fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T08:17:10.526222Z",
     "iopub.status.busy": "2023-07-04T08:17:10.525889Z",
     "iopub.status.idle": "2023-07-04T10:56:09.844615Z",
     "shell.execute_reply": "2023-07-04T10:56:09.843495Z"
    },
    "papermill": {
     "duration": 9539.465918,
     "end_time": "2023-07-04T10:56:09.928644",
     "exception": false,
     "start_time": "2023-07-04T08:17:10.462726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Loading Dataset\n",
      "(142246, 2304)\n",
      "## Running Training\n",
      "#### Seed:  42 ####\n",
      "\n",
      "Epoch: 0\n",
      "Train loss: 144.75735007886075\n",
      "Train score: 0.07281005254274257\n",
      "Score Improved (0.0 ---> 0.07281005254274257)\n",
      "Epoch: 1\n",
      "Train loss: 133.7402452596229\n",
      "Train score: 0.09324490400759396\n",
      "Score Improved (0.0 ---> 0.09324490400759396)\n",
      "Epoch: 2\n",
      "Train loss: 130.02964778145125\n",
      "Train score: 0.11598902183173687\n",
      "Score Improved (0.0 ---> 0.11598902183173687)\n",
      "Epoch: 3\n",
      "Train loss: 128.24593204476676\n",
      "Train score: 0.12253575097280445\n",
      "Score Improved (0.0 ---> 0.12253575097280445)\n",
      "Epoch: 4\n",
      "Train loss: 127.14104035977962\n",
      "Train score: 0.1262848566815691\n",
      "Score Improved (0.0 ---> 0.1262848566815691)\n",
      "Epoch: 5\n",
      "Train loss: 126.23439418992838\n",
      "Train score: 0.1300298552724194\n",
      "Score Improved (0.0 ---> 0.1300298552724194)\n",
      "Epoch: 6\n",
      "Train loss: 125.518553835451\n",
      "Train score: 0.13289363480383756\n",
      "Score Improved (0.0 ---> 0.13289363480383756)\n",
      "Epoch: 7\n",
      "Train loss: 124.84073857372239\n",
      "Train score: 0.13579785334840677\n",
      "Score Improved (0.0 ---> 0.13579785334840677)\n",
      "Epoch: 8\n",
      "Train loss: 124.21396774708845\n",
      "Train score: 0.138446070282657\n",
      "Score Improved (0.0 ---> 0.138446070282657)\n",
      "Epoch: 9\n",
      "Train loss: 123.62086684472894\n",
      "Train score: 0.14176152380083532\n",
      "Score Improved (0.0 ---> 0.14176152380083532)\n",
      "Epoch: 10\n",
      "Train loss: 123.01945785439433\n",
      "Train score: 0.1449143648700277\n",
      "Score Improved (0.0 ---> 0.1449143648700277)\n",
      "Epoch: 11\n",
      "Train loss: 122.44435828107164\n",
      "Train score: 0.14863379032239787\n",
      "Score Improved (0.0 ---> 0.14863379032239787)\n",
      "Epoch: 12\n",
      "Train loss: 121.92723484837667\n",
      "Train score: 0.15210089965804785\n",
      "Score Improved (0.0 ---> 0.15210089965804785)\n",
      "Epoch: 13\n",
      "Train loss: 121.43268219595284\n",
      "Train score: 0.15569002946986626\n",
      "Score Improved (0.0 ---> 0.15569002946986626)\n",
      "Epoch: 14\n",
      "Train loss: 120.93314523647153\n",
      "Train score: 0.15920362868843932\n",
      "Score Improved (0.0 ---> 0.15920362868843932)\n",
      "Epoch: 15\n",
      "Train loss: 120.4439325264659\n",
      "Train score: 0.1627063825381861\n",
      "Score Improved (0.0 ---> 0.1627063825381861)\n",
      "Epoch: 16\n",
      "Train loss: 120.04736696169833\n",
      "Train score: 0.16642989976859013\n",
      "Score Improved (0.0 ---> 0.16642989976859013)\n",
      "Epoch: 17\n",
      "Train loss: 119.60218156106295\n",
      "Train score: 0.17018503192718185\n",
      "Score Improved (0.0 ---> 0.17018503192718185)\n",
      "Epoch: 18\n",
      "Train loss: 119.18148730059063\n",
      "Train score: 0.17365688666031506\n",
      "Score Improved (0.0 ---> 0.17365688666031506)\n",
      "Epoch: 19\n",
      "Train loss: 118.7392321317454\n",
      "Train score: 0.177261104582634\n",
      "Score Improved (0.0 ---> 0.177261104582634)\n",
      "Epoch: 20\n",
      "Train loss: 118.44408021746156\n",
      "Train score: 0.1805490390447433\n",
      "Score Improved (0.0 ---> 0.1805490390447433)\n",
      "Epoch: 21\n",
      "Train loss: 118.05948575733734\n",
      "Train score: 0.18424161365094782\n",
      "Score Improved (0.0 ---> 0.18424161365094782)\n",
      "Epoch: 22\n",
      "Train loss: 117.75104442241532\n",
      "Train score: 0.18772203310821917\n",
      "Score Improved (0.0 ---> 0.18772203310821917)\n",
      "Epoch: 23\n",
      "Train loss: 117.45156485033795\n",
      "Train score: 0.1909895657042377\n",
      "Score Improved (0.0 ---> 0.1909895657042377)\n",
      "Epoch: 24\n",
      "Train loss: 117.1337077625657\n",
      "Train score: 0.1941988917629062\n",
      "Score Improved (0.0 ---> 0.1941988917629062)\n",
      "Epoch: 25\n",
      "Train loss: 116.82746088331986\n",
      "Train score: 0.19774751083997988\n",
      "Score Improved (0.0 ---> 0.19774751083997988)\n",
      "Epoch: 26\n",
      "Train loss: 116.55933358125789\n",
      "Train score: 0.20144515154138737\n",
      "Score Improved (0.0 ---> 0.20144515154138737)\n",
      "Epoch: 27\n",
      "Train loss: 116.27580536014393\n",
      "Train score: 0.20423527525527663\n",
      "Score Improved (0.0 ---> 0.20423527525527663)\n",
      "Epoch: 28\n",
      "Train loss: 116.03768067422745\n",
      "Train score: 0.20701673527150793\n",
      "Score Improved (0.0 ---> 0.20701673527150793)\n",
      "Epoch: 29\n",
      "Train loss: 115.77704047344164\n",
      "Train score: 0.21024132913812574\n",
      "Score Improved (0.0 ---> 0.21024132913812574)\n",
      "Epoch: 30\n",
      "Train loss: 115.51804789545069\n",
      "Train score: 0.21318366786686688\n",
      "Score Improved (0.0 ---> 0.21318366786686688)\n",
      "Epoch: 31\n",
      "Train loss: 115.33368515197652\n",
      "Train score: 0.2163643843042581\n",
      "Score Improved (0.0 ---> 0.2163643843042581)\n",
      "Epoch: 32\n",
      "Train loss: 115.1967227409576\n",
      "Train score: 0.21874705237964692\n",
      "Score Improved (0.0 ---> 0.21874705237964692)\n",
      "Epoch: 33\n",
      "Train loss: 114.89551888817152\n",
      "Train score: 0.2218284131319151\n",
      "Score Improved (0.0 ---> 0.2218284131319151)\n",
      "Epoch: 34\n",
      "Train loss: 114.7399267894959\n",
      "Train score: 0.22494483100134843\n",
      "Score Improved (0.0 ---> 0.22494483100134843)\n",
      "Epoch: 35\n",
      "Train loss: 114.5418406655556\n",
      "Train score: 0.22710424330061788\n",
      "Score Improved (0.0 ---> 0.22710424330061788)\n",
      "Epoch: 36\n",
      "Train loss: 114.34201997903624\n",
      "Train score: 0.23026297770939952\n",
      "Score Improved (0.0 ---> 0.23026297770939952)\n",
      "Epoch: 37\n",
      "Train loss: 114.18823682339513\n",
      "Train score: 0.2323124383299671\n",
      "Score Improved (0.0 ---> 0.2323124383299671)\n",
      "Epoch: 38\n",
      "Train loss: 114.00048096411967\n",
      "Train score: 0.23533787830126054\n",
      "Score Improved (0.0 ---> 0.23533787830126054)\n",
      "Epoch: 39\n",
      "Train loss: 113.8205800366268\n",
      "Train score: 0.2378762598832057\n",
      "Score Improved (0.0 ---> 0.2378762598832057)\n",
      "Epoch: 40\n",
      "Train loss: 113.71377376160945\n",
      "Train score: 0.24001192807893126\n",
      "Score Improved (0.0 ---> 0.24001192807893126)\n",
      "Epoch: 41\n",
      "Train loss: 113.51004548807148\n",
      "Train score: 0.24248160245752998\n",
      "Score Improved (0.0 ---> 0.24248160245752998)\n",
      "Epoch: 42\n",
      "Train loss: 113.3891170405112\n",
      "Train score: 0.2446392905397356\n",
      "Score Improved (0.0 ---> 0.2446392905397356)\n",
      "Epoch: 43\n",
      "Train loss: 113.24273215067906\n",
      "Train score: 0.24732182988573506\n",
      "Score Improved (0.0 ---> 0.24732182988573506)\n",
      "Epoch: 44\n",
      "Train loss: 113.08265991519876\n",
      "Train score: 0.2491981079737361\n",
      "Score Improved (0.0 ---> 0.2491981079737361)\n",
      "Epoch: 45\n",
      "Train loss: 112.93665909414834\n",
      "Train score: 0.2516558580012017\n",
      "Score Improved (0.0 ---> 0.2516558580012017)\n",
      "Epoch: 46\n",
      "Train loss: 112.80242168406723\n",
      "Train score: 0.2539749790890276\n",
      "Score Improved (0.0 ---> 0.2539749790890276)\n",
      "Epoch: 47\n",
      "Train loss: 112.69906844975849\n",
      "Train score: 0.25617914276938103\n",
      "Score Improved (0.0 ---> 0.25617914276938103)\n",
      "Epoch: 48\n",
      "Train loss: 112.50710115354566\n",
      "Train score: 0.2581208355556887\n",
      "Score Improved (0.0 ---> 0.2581208355556887)\n",
      "Epoch: 49\n",
      "Train loss: 112.411410951843\n",
      "Train score: 0.25977702703047606\n",
      "Score Improved (0.0 ---> 0.25977702703047606)\n",
      "Epoch: 50\n",
      "Train loss: 112.32434377743634\n",
      "Train score: 0.261723687623573\n",
      "Score Improved (0.0 ---> 0.261723687623573)\n",
      "Epoch: 51\n",
      "Train loss: 112.20930866851663\n",
      "Train score: 0.2636876414128331\n",
      "Score Improved (0.0 ---> 0.2636876414128331)\n",
      "Epoch: 52\n",
      "Train loss: 112.06263036574911\n",
      "Train score: 0.26576773385117747\n",
      "Score Improved (0.0 ---> 0.26576773385117747)\n",
      "Epoch: 53\n",
      "Train loss: 111.95481296763127\n",
      "Train score: 0.267036731752953\n",
      "Score Improved (0.0 ---> 0.267036731752953)\n",
      "Epoch: 54\n",
      "Train loss: 111.87833422358634\n",
      "Train score: 0.2685168434862643\n",
      "Score Improved (0.0 ---> 0.2685168434862643)\n",
      "Epoch: 55\n",
      "Train loss: 111.7630213834876\n",
      "Train score: 0.2708427877111074\n",
      "Score Improved (0.0 ---> 0.2708427877111074)\n",
      "Epoch: 56\n",
      "Train loss: 111.6613257523069\n",
      "Train score: 0.2735701699040378\n",
      "Score Improved (0.0 ---> 0.2735701699040378)\n",
      "Epoch: 57\n",
      "Train loss: 111.53997139524238\n",
      "Train score: 0.27495159228154475\n",
      "Score Improved (0.0 ---> 0.27495159228154475)\n",
      "Epoch: 58\n",
      "Train loss: 111.43986712759418\n",
      "Train score: 0.27629068430360776\n",
      "Score Improved (0.0 ---> 0.27629068430360776)\n",
      "Epoch: 59\n",
      "Train loss: 111.33741987517031\n",
      "Train score: 0.2778142034067185\n",
      "Score Improved (0.0 ---> 0.2778142034067185)\n",
      "Epoch: 60\n",
      "Train loss: 111.27311022629638\n",
      "Train score: 0.2789337287546956\n",
      "Score Improved (0.0 ---> 0.2789337287546956)\n",
      "Epoch: 61\n",
      "Train loss: 111.17305541492736\n",
      "Train score: 0.28083784347872914\n",
      "Score Improved (0.0 ---> 0.28083784347872914)\n",
      "Epoch: 62\n",
      "Train loss: 111.06384270875343\n",
      "Train score: 0.28187453529154016\n",
      "Score Improved (0.0 ---> 0.28187453529154016)\n",
      "Epoch: 63\n",
      "Train loss: 110.96620018872439\n",
      "Train score: 0.2835038566743389\n",
      "Score Improved (0.0 ---> 0.2835038566743389)\n",
      "Epoch: 64\n",
      "Train loss: 110.92122311826287\n",
      "Train score: 0.28482431789752416\n",
      "Score Improved (0.0 ---> 0.28482431789752416)\n",
      "Epoch: 65\n",
      "Train loss: 110.82627605646712\n",
      "Train score: 0.286558587963974\n",
      "Score Improved (0.0 ---> 0.286558587963974)\n",
      "Epoch: 66\n",
      "Train loss: 110.73528928987211\n",
      "Train score: 0.28780988722550627\n",
      "Score Improved (0.0 ---> 0.28780988722550627)\n",
      "Epoch: 67\n",
      "Train loss: 110.63899337401476\n",
      "Train score: 0.2897628994000641\n",
      "Score Improved (0.0 ---> 0.2897628994000641)\n",
      "Epoch: 68\n",
      "Train loss: 110.5438975383284\n",
      "Train score: 0.2912679746510896\n",
      "Score Improved (0.0 ---> 0.2912679746510896)\n",
      "Epoch: 69\n",
      "Train loss: 110.48863904921976\n",
      "Train score: 0.2927246329296581\n",
      "Score Improved (0.0 ---> 0.2927246329296581)\n",
      "Epoch: 70\n",
      "Train loss: 110.41011679947712\n",
      "Train score: 0.2943357260068845\n",
      "Score Improved (0.0 ---> 0.2943357260068845)\n",
      "Epoch: 71\n",
      "Train loss: 110.33183319661188\n",
      "Train score: 0.29529130732706593\n",
      "Score Improved (0.0 ---> 0.29529130732706593)\n",
      "Epoch: 72\n",
      "Train loss: 110.28180078096938\n",
      "Train score: 0.29662984461562314\n",
      "Score Improved (0.0 ---> 0.29662984461562314)\n",
      "Epoch: 73\n",
      "Train loss: 110.15638157307775\n",
      "Train score: 0.2980643961077715\n",
      "Score Improved (0.0 ---> 0.2980643961077715)\n",
      "Epoch: 74\n",
      "Train loss: 110.0957915216239\n",
      "Train score: 0.299469912737512\n",
      "Score Improved (0.0 ---> 0.299469912737512)\n",
      "Epoch: 75\n",
      "Train loss: 110.02946847249741\n",
      "Train score: 0.30064498210046164\n",
      "Score Improved (0.0 ---> 0.30064498210046164)\n",
      "Epoch: 76\n",
      "Train loss: 109.97629256459193\n",
      "Train score: 0.30173193068625886\n",
      "Score Improved (0.0 ---> 0.30173193068625886)\n",
      "Epoch: 77\n",
      "Train loss: 109.91992181256862\n",
      "Train score: 0.30284121530501473\n",
      "Score Improved (0.0 ---> 0.30284121530501473)\n",
      "Epoch: 78\n",
      "Train loss: 109.8379345187712\n",
      "Train score: 0.3042930066489165\n",
      "Score Improved (0.0 ---> 0.3042930066489165)\n",
      "Epoch: 79\n",
      "Train loss: 109.7870778757902\n",
      "Train score: 0.30474427181173996\n",
      "Score Improved (0.0 ---> 0.30474427181173996)\n",
      "Epoch: 80\n",
      "Train loss: 109.72423920825099\n",
      "Train score: 0.3062760166470521\n",
      "Score Improved (0.0 ---> 0.3062760166470521)\n",
      "Epoch: 81\n",
      "Train loss: 109.68248127554804\n",
      "Train score: 0.3080544143744633\n",
      "Score Improved (0.0 ---> 0.3080544143744633)\n",
      "Epoch: 82\n",
      "Train loss: 109.59976838002207\n",
      "Train score: 0.30861897332165844\n",
      "Score Improved (0.0 ---> 0.30861897332165844)\n",
      "Epoch: 83\n",
      "Train loss: 109.52240026717047\n",
      "Train score: 0.3095903097389\n",
      "Score Improved (0.0 ---> 0.3095903097389)\n",
      "Epoch: 84\n",
      "Train loss: 109.41601976574573\n",
      "Train score: 0.311527847903465\n",
      "Score Improved (0.0 ---> 0.311527847903465)\n",
      "Epoch: 85\n",
      "Train loss: 109.40006772589165\n",
      "Train score: 0.31204349205961995\n",
      "Score Improved (0.0 ---> 0.31204349205961995)\n",
      "Epoch: 86\n",
      "Train loss: 109.35614272333054\n",
      "Train score: 0.3136757701246086\n",
      "Score Improved (0.0 ---> 0.3136757701246086)\n",
      "Epoch: 87\n",
      "Train loss: 109.29262186758427\n",
      "Train score: 0.3148996513932698\n",
      "Score Improved (0.0 ---> 0.3148996513932698)\n",
      "Epoch: 88\n",
      "Train loss: 109.21461034971917\n",
      "Train score: 0.3161164240146175\n",
      "Score Improved (0.0 ---> 0.3161164240146175)\n",
      "Epoch: 89\n",
      "Train loss: 109.1638262634891\n",
      "Train score: 0.316701412421754\n",
      "Score Improved (0.0 ---> 0.316701412421754)\n",
      "Epoch: 90\n",
      "Train loss: 109.10320088498754\n",
      "Train score: 0.3182991307808682\n",
      "Score Improved (0.0 ---> 0.3182991307808682)\n",
      "Epoch: 91\n",
      "Train loss: 109.09170472659295\n",
      "Train score: 0.31914198506866176\n",
      "Score Improved (0.0 ---> 0.31914198506866176)\n",
      "Epoch: 92\n",
      "Train loss: 109.03361241981699\n",
      "Train score: 0.32005014632948386\n",
      "Score Improved (0.0 ---> 0.32005014632948386)\n",
      "Epoch: 93\n",
      "Train loss: 108.97809586917104\n",
      "Train score: 0.3207938670919309\n",
      "Score Improved (0.0 ---> 0.3207938670919309)\n",
      "Epoch: 94\n",
      "Train loss: 108.900159500354\n",
      "Train score: 0.3223260754511357\n",
      "Score Improved (0.0 ---> 0.3223260754511357)\n",
      "Epoch: 95\n",
      "Train loss: 108.87837900695119\n",
      "Train score: 0.3227363076540951\n",
      "Score Improved (0.0 ---> 0.3227363076540951)\n",
      "Epoch: 96\n",
      "Train loss: 108.79583509442053\n",
      "Train score: 0.32315572293800354\n",
      "Score Improved (0.0 ---> 0.32315572293800354)\n",
      "Epoch: 97\n",
      "Train loss: 108.74069072366768\n",
      "Train score: 0.32479045750455454\n",
      "Score Improved (0.0 ---> 0.32479045750455454)\n",
      "Epoch: 98\n",
      "Train loss: 108.66001174343421\n",
      "Train score: 0.32661836757459184\n",
      "Score Improved (0.0 ---> 0.32661836757459184)\n",
      "Epoch: 99\n",
      "Train loss: 108.61865606946645\n",
      "Train score: 0.3273203970987949\n",
      "Score Improved (0.0 ---> 0.3273203970987949)\n",
      "Epoch: 100\n",
      "Train loss: 108.61820896729498\n",
      "Train score: 0.32780677866161706\n",
      "Score Improved (0.0 ---> 0.32780677866161706)\n",
      "Epoch: 101\n",
      "Train loss: 108.58803272205748\n",
      "Train score: 0.3284593349654728\n",
      "Score Improved (0.0 ---> 0.3284593349654728)\n",
      "Epoch: 102\n",
      "Train loss: 108.53864865723875\n",
      "Train score: 0.329275805897904\n",
      "Score Improved (0.0 ---> 0.329275805897904)\n",
      "Epoch: 103\n",
      "Train loss: 108.47355374969044\n",
      "Train score: 0.33068282364442986\n",
      "Score Improved (0.0 ---> 0.33068282364442986)\n",
      "Epoch: 104\n",
      "Train loss: 108.42095369335476\n",
      "Train score: 0.33175588078670004\n",
      "Score Improved (0.0 ---> 0.33175588078670004)\n",
      "Epoch: 105\n",
      "Train loss: 108.38884041561208\n",
      "Train score: 0.3327042446869366\n",
      "Score Improved (0.0 ---> 0.3327042446869366)\n",
      "Epoch: 106\n",
      "Train loss: 108.33373651659656\n",
      "Train score: 0.33386451433508885\n",
      "Score Improved (0.0 ---> 0.33386451433508885)\n",
      "Epoch: 107\n",
      "Train loss: 108.27233869351667\n",
      "Train score: 0.33476661660522294\n",
      "Score Improved (0.0 ---> 0.33476661660522294)\n",
      "Epoch: 108\n",
      "Train loss: 108.27756067247064\n",
      "Train score: 0.3353807786466629\n",
      "Score Improved (0.0 ---> 0.3353807786466629)\n",
      "Epoch: 109\n",
      "Train loss: 108.20900265720603\n",
      "Train score: 0.3354356202054389\n",
      "Score Improved (0.0 ---> 0.3354356202054389)\n",
      "Epoch: 110\n",
      "Train loss: 108.16070159815136\n",
      "Train score: 0.337041347987197\n",
      "Score Improved (0.0 ---> 0.337041347987197)\n",
      "Epoch: 111\n",
      "Train loss: 108.10591503369812\n",
      "Train score: 0.33758303676720164\n",
      "Score Improved (0.0 ---> 0.33758303676720164)\n",
      "Epoch: 112\n",
      "Train loss: 108.10531188073212\n",
      "Train score: 0.3389157693789482\n",
      "Score Improved (0.0 ---> 0.3389157693789482)\n",
      "Epoch: 113\n",
      "Train loss: 108.0287638878344\n",
      "Train score: 0.34003060336922397\n",
      "Score Improved (0.0 ---> 0.34003060336922397)\n",
      "Epoch: 114\n",
      "Train loss: 108.00628656810215\n",
      "Train score: 0.34063244757484606\n",
      "Score Improved (0.0 ---> 0.34063244757484606)\n",
      "Epoch: 115\n",
      "Train loss: 107.94901255500106\n",
      "Train score: 0.342142809101586\n",
      "Score Improved (0.0 ---> 0.342142809101586)\n",
      "Epoch: 116\n",
      "Train loss: 107.922241848982\n",
      "Train score: 0.34313432664605586\n",
      "Score Improved (0.0 ---> 0.34313432664605586)\n",
      "Epoch: 117\n",
      "Train loss: 107.89269160616946\n",
      "Train score: 0.3433953934012289\n",
      "Score Improved (0.0 ---> 0.3433953934012289)\n",
      "Epoch: 118\n",
      "Train loss: 107.82139047220657\n",
      "Train score: 0.34499005302207525\n",
      "Score Improved (0.0 ---> 0.34499005302207525)\n",
      "Epoch: 119\n",
      "Train loss: 107.78910649138729\n",
      "Train score: 0.3447292544689476\n",
      "Score Improved (0.0 ---> 0.3447292544689476)\n",
      "Epoch: 120\n",
      "Train loss: 107.80309956375761\n",
      "Train score: 0.344365400398478\n",
      "Score Improved (0.0 ---> 0.344365400398478)\n",
      "Epoch: 121\n",
      "Train loss: 107.71385056659106\n",
      "Train score: 0.3460099098824805\n",
      "Score Improved (0.0 ---> 0.3460099098824805)\n",
      "Epoch: 122\n",
      "Train loss: 107.70851741964711\n",
      "Train score: 0.34695410904947965\n",
      "Score Improved (0.0 ---> 0.34695410904947965)\n",
      "Epoch: 123\n",
      "Train loss: 107.63403170455715\n",
      "Train score: 0.3482492493005584\n",
      "Score Improved (0.0 ---> 0.3482492493005584)\n",
      "Epoch: 124\n",
      "Train loss: 107.62167206149522\n",
      "Train score: 0.3483250895225564\n",
      "Score Improved (0.0 ---> 0.3483250895225564)\n",
      "Epoch: 125\n",
      "Train loss: 107.57797622997111\n",
      "Train score: 0.35005803063915997\n",
      "Score Improved (0.0 ---> 0.35005803063915997)\n",
      "Epoch: 126\n",
      "Train loss: 107.57131717958052\n",
      "Train score: 0.3503193452405579\n",
      "Score Improved (0.0 ---> 0.3503193452405579)\n",
      "Epoch: 127\n",
      "Train loss: 107.50123156189572\n",
      "Train score: 0.3505765062924983\n",
      "Score Improved (0.0 ---> 0.3505765062924983)\n",
      "Epoch: 128\n",
      "Train loss: 107.4777780100564\n",
      "Train score: 0.3512260035798535\n",
      "Score Improved (0.0 ---> 0.3512260035798535)\n",
      "Epoch: 129\n",
      "Train loss: 107.44365970033438\n",
      "Train score: 0.3520021288503841\n",
      "Score Improved (0.0 ---> 0.3520021288503841)\n",
      "Epoch: 130\n",
      "Train loss: 107.38888555758196\n",
      "Train score: 0.3539485847997918\n",
      "Score Improved (0.0 ---> 0.3539485847997918)\n",
      "Epoch: 131\n",
      "Train loss: 107.39995497094297\n",
      "Train score: 0.3543282524188093\n",
      "Score Improved (0.0 ---> 0.3543282524188093)\n",
      "Epoch: 132\n",
      "Train loss: 107.3763915763325\n",
      "Train score: 0.3543756997328183\n",
      "Score Improved (0.0 ---> 0.3543756997328183)\n",
      "Epoch: 133\n",
      "Train loss: 107.34032193914102\n",
      "Train score: 0.3549228180666289\n",
      "Score Improved (0.0 ---> 0.3549228180666289)\n",
      "Epoch: 134\n",
      "Train loss: 107.29105240127114\n",
      "Train score: 0.35655422950725213\n",
      "Score Improved (0.0 ---> 0.35655422950725213)\n",
      "Epoch: 135\n",
      "Train loss: 107.21433698530466\n",
      "Train score: 0.3574066787977839\n",
      "Score Improved (0.0 ---> 0.3574066787977839)\n",
      "Epoch: 136\n",
      "Train loss: 107.22013046794349\n",
      "Train score: 0.35702661711834127\n",
      "Score Improved (0.0 ---> 0.35702661711834127)\n",
      "Epoch: 137\n",
      "Train loss: 107.23573027816563\n",
      "Train score: 0.3569555904195562\n",
      "Score Improved (0.0 ---> 0.3569555904195562)\n",
      "Epoch: 138\n",
      "Train loss: 107.13712026996376\n",
      "Train score: 0.3590946657674753\n",
      "Score Improved (0.0 ---> 0.3590946657674753)\n",
      "Epoch: 139\n",
      "Train loss: 107.14698567426713\n",
      "Train score: 0.35897964541321387\n",
      "Score Improved (0.0 ---> 0.35897964541321387)\n",
      "Epoch: 140\n",
      "Train loss: 107.12859036047765\n",
      "Train score: 0.359429447970173\n",
      "Score Improved (0.0 ---> 0.359429447970173)\n",
      "Epoch: 141\n",
      "Train loss: 107.11544410573946\n",
      "Train score: 0.3602895377581442\n",
      "Score Improved (0.0 ---> 0.3602895377581442)\n",
      "Epoch: 142\n",
      "Train loss: 106.99601416242352\n",
      "Train score: 0.3614620048754774\n",
      "Score Improved (0.0 ---> 0.3614620048754774)\n",
      "Epoch: 143\n",
      "Train loss: 107.0058660411061\n",
      "Train score: 0.36122813556769306\n",
      "Score Improved (0.0 ---> 0.36122813556769306)\n",
      "Epoch: 144\n",
      "Train loss: 106.99239404437871\n",
      "Train score: 0.362063866833517\n",
      "Score Improved (0.0 ---> 0.362063866833517)\n",
      "Epoch: 145\n",
      "Train loss: 106.94391746516169\n",
      "Train score: 0.3633484020084384\n",
      "Score Improved (0.0 ---> 0.3633484020084384)\n",
      "Epoch: 146\n",
      "Train loss: 106.91263652000364\n",
      "Train score: 0.36336700080553097\n",
      "Score Improved (0.0 ---> 0.36336700080553097)\n",
      "Epoch: 147\n",
      "Train loss: 106.8663432423766\n",
      "Train score: 0.36404782896772786\n",
      "Score Improved (0.0 ---> 0.36404782896772786)\n",
      "Epoch: 148\n",
      "Train loss: 106.85683140214928\n",
      "Train score: 0.3643994548683043\n",
      "Score Improved (0.0 ---> 0.3643994548683043)\n",
      "Epoch: 149\n",
      "Train loss: 106.83388616924651\n",
      "Train score: 0.3660286507157915\n",
      "Score Improved (0.0 ---> 0.3660286507157915)\n",
      "Epoch: 150\n",
      "Train loss: 106.80093246279102\n",
      "Train score: 0.3663886488728483\n",
      "Score Improved (0.0 ---> 0.3663886488728483)\n",
      "Epoch: 151\n",
      "Train loss: 106.79896202606055\n",
      "Train score: 0.36604244643638595\n",
      "Score Improved (0.0 ---> 0.36604244643638595)\n",
      "Epoch: 152\n",
      "Train loss: 106.73639185940199\n",
      "Train score: 0.36650939094700663\n",
      "Score Improved (0.0 ---> 0.36650939094700663)\n",
      "Epoch: 153\n",
      "Train loss: 106.71385408055569\n",
      "Train score: 0.36746553548092387\n",
      "Score Improved (0.0 ---> 0.36746553548092387)\n",
      "Epoch: 154\n",
      "Train loss: 106.71906311068196\n",
      "Train score: 0.36870857966299353\n",
      "Score Improved (0.0 ---> 0.36870857966299353)\n",
      "Epoch: 155\n",
      "Train loss: 106.67794047163196\n",
      "Train score: 0.36937117315085555\n",
      "Score Improved (0.0 ---> 0.36937117315085555)\n",
      "Epoch: 156\n",
      "Train loss: 106.6262008908136\n",
      "Train score: 0.369950281309585\n",
      "Score Improved (0.0 ---> 0.369950281309585)\n",
      "Epoch: 157\n",
      "Train loss: 106.58016890667454\n",
      "Train score: 0.37038362439624767\n",
      "Score Improved (0.0 ---> 0.37038362439624767)\n",
      "Epoch: 158\n",
      "Train loss: 106.587134939924\n",
      "Train score: 0.3718751762360081\n",
      "Score Improved (0.0 ---> 0.3718751762360081)\n",
      "Epoch: 159\n",
      "Train loss: 106.53506818773803\n",
      "Train score: 0.37223714562081756\n",
      "Score Improved (0.0 ---> 0.37223714562081756)\n",
      "Epoch: 160\n",
      "Train loss: 106.5247456675689\n",
      "Train score: 0.37375699658111133\n",
      "Score Improved (0.0 ---> 0.37375699658111133)\n",
      "Epoch: 161\n",
      "Train loss: 106.50450476352006\n",
      "Train score: 0.3732265536022634\n",
      "Score Improved (0.0 ---> 0.3732265536022634)\n",
      "Epoch: 162\n",
      "Train loss: 106.51929894741744\n",
      "Train score: 0.3740136275026049\n",
      "Score Improved (0.0 ---> 0.3740136275026049)\n",
      "Epoch: 163\n",
      "Train loss: 106.44287405205382\n",
      "Train score: 0.3747600382105273\n",
      "Score Improved (0.0 ---> 0.3747600382105273)\n",
      "Epoch: 164\n",
      "Train loss: 106.41631089703914\n",
      "Train score: 0.3749196156078964\n",
      "Score Improved (0.0 ---> 0.3749196156078964)\n",
      "Epoch: 165\n",
      "Train loss: 106.40869123064832\n",
      "Train score: 0.37494174477905645\n",
      "Score Improved (0.0 ---> 0.37494174477905645)\n",
      "Epoch: 166\n",
      "Train loss: 106.41423799699196\n",
      "Train score: 0.3748329635334235\n",
      "Score Improved (0.0 ---> 0.3748329635334235)\n",
      "Epoch: 167\n",
      "Train loss: 106.35374511216295\n",
      "Train score: 0.37688098618135546\n",
      "Score Improved (0.0 ---> 0.37688098618135546)\n",
      "Epoch: 168\n",
      "Train loss: 106.32300166371196\n",
      "Train score: 0.37777836584876245\n",
      "Score Improved (0.0 ---> 0.37777836584876245)\n",
      "Epoch: 169\n",
      "Train loss: 106.34457266859194\n",
      "Train score: 0.37720415100107285\n",
      "Score Improved (0.0 ---> 0.37720415100107285)\n",
      "Epoch: 170\n",
      "Train loss: 106.31550813961901\n",
      "Train score: 0.3779971700991313\n",
      "Score Improved (0.0 ---> 0.3779971700991313)\n",
      "Epoch: 171\n",
      "Train loss: 106.3060581007806\n",
      "Train score: 0.37788852609553314\n",
      "Score Improved (0.0 ---> 0.37788852609553314)\n",
      "Epoch: 172\n",
      "Train loss: 106.24610711621693\n",
      "Train score: 0.3793571977433466\n",
      "Score Improved (0.0 ---> 0.3793571977433466)\n",
      "Epoch: 173\n",
      "Train loss: 106.19150254837804\n",
      "Train score: 0.3792087144956642\n",
      "Score Improved (0.0 ---> 0.3792087144956642)\n",
      "Epoch: 174\n",
      "Train loss: 106.1594902723925\n",
      "Train score: 0.3804713289635761\n",
      "Score Improved (0.0 ---> 0.3804713289635761)\n",
      "Epoch: 175\n",
      "Train loss: 106.2029152897492\n",
      "Train score: 0.38015569365286206\n",
      "Score Improved (0.0 ---> 0.38015569365286206)\n",
      "Epoch: 176\n",
      "Train loss: 106.15652291462962\n",
      "Train score: 0.38047707542690534\n",
      "Score Improved (0.0 ---> 0.38047707542690534)\n",
      "Epoch: 177\n",
      "Train loss: 106.10431477573094\n",
      "Train score: 0.3818044713521224\n",
      "Score Improved (0.0 ---> 0.3818044713521224)\n",
      "Epoch: 178\n",
      "Train loss: 106.05969574992392\n",
      "Train score: 0.3816035247163497\n",
      "Score Improved (0.0 ---> 0.3816035247163497)\n",
      "Epoch: 179\n",
      "Train loss: 106.04537337643893\n",
      "Train score: 0.3824025058225741\n",
      "Score Improved (0.0 ---> 0.3824025058225741)\n",
      "Epoch: 180\n",
      "Train loss: 106.07562143783234\n",
      "Train score: 0.3826145518659605\n",
      "Score Improved (0.0 ---> 0.3826145518659605)\n",
      "Epoch: 181\n",
      "Train loss: 105.99564501828348\n",
      "Train score: 0.384074320765228\n",
      "Score Improved (0.0 ---> 0.384074320765228)\n",
      "Epoch: 182\n",
      "Train loss: 106.03780228574433\n",
      "Train score: 0.38517998230605976\n",
      "Score Improved (0.0 ---> 0.38517998230605976)\n",
      "Epoch: 183\n",
      "Train loss: 105.98423967009737\n",
      "Train score: 0.3852536445449389\n",
      "Score Improved (0.0 ---> 0.3852536445449389)\n",
      "Epoch: 184\n",
      "Train loss: 105.95565409306548\n",
      "Train score: 0.3865419833209221\n",
      "Score Improved (0.0 ---> 0.3865419833209221)\n",
      "Epoch: 185\n",
      "Train loss: 105.94047518217505\n",
      "Train score: 0.387054573009094\n",
      "Score Improved (0.0 ---> 0.387054573009094)\n",
      "Epoch: 186\n",
      "Train loss: 105.91837559400956\n",
      "Train score: 0.3873126214434845\n",
      "Score Improved (0.0 ---> 0.3873126214434845)\n",
      "Epoch: 187\n",
      "Train loss: 105.91347430417862\n",
      "Train score: 0.38727757566178633\n",
      "Score Improved (0.0 ---> 0.38727757566178633)\n",
      "Epoch: 188\n",
      "Train loss: 105.91014505086022\n",
      "Train score: 0.3864518470430817\n",
      "Score Improved (0.0 ---> 0.3864518470430817)\n",
      "Epoch: 189\n",
      "Train loss: 105.88285359261856\n",
      "Train score: 0.3878888134979959\n",
      "Score Improved (0.0 ---> 0.3878888134979959)\n",
      "Epoch: 190\n",
      "Train loss: 105.84799807354243\n",
      "Train score: 0.3878615311984429\n",
      "Score Improved (0.0 ---> 0.3878615311984429)\n",
      "Epoch: 191\n",
      "Train loss: 105.820230563523\n",
      "Train score: 0.38836453818980576\n",
      "Score Improved (0.0 ---> 0.38836453818980576)\n",
      "Epoch: 192\n",
      "Train loss: 105.82258504243212\n",
      "Train score: 0.3882974671353412\n",
      "Score Improved (0.0 ---> 0.3882974671353412)\n",
      "Epoch: 193\n",
      "Train loss: 105.80219598365758\n",
      "Train score: 0.38887128498482054\n",
      "Score Improved (0.0 ---> 0.38887128498482054)\n",
      "Epoch: 194\n",
      "Train loss: 105.7674945417074\n",
      "Train score: 0.3899990087600664\n",
      "Score Improved (0.0 ---> 0.3899990087600664)\n",
      "Epoch: 195\n",
      "Train loss: 105.78348796316658\n",
      "Train score: 0.38977513507695966\n",
      "Score Improved (0.0 ---> 0.38977513507695966)\n",
      "Epoch: 196\n",
      "Train loss: 105.73009774107088\n",
      "Train score: 0.3908414808223797\n",
      "Score Improved (0.0 ---> 0.3908414808223797)\n",
      "Epoch: 197\n",
      "Train loss: 105.70901396329442\n",
      "Train score: 0.3909398128691935\n",
      "Score Improved (0.0 ---> 0.3909398128691935)\n",
      "Epoch: 198\n",
      "Train loss: 105.68065050587806\n",
      "Train score: 0.39236931976631695\n",
      "Score Improved (0.0 ---> 0.39236931976631695)\n",
      "Epoch: 199\n",
      "Train loss: 105.6537336523775\n",
      "Train score: 0.391214488157229\n",
      "Score Improved (0.0 ---> 0.391214488157229)\n",
      "Epoch: 200\n",
      "Train loss: 105.65640570216564\n",
      "Train score: 0.3927458070028221\n",
      "Score Improved (0.0 ---> 0.3927458070028221)\n",
      "Epoch: 201\n",
      "Train loss: 105.59554241276909\n",
      "Train score: 0.3925027608755809\n",
      "Score Improved (0.0 ---> 0.3925027608755809)\n",
      "Epoch: 202\n",
      "Train loss: 105.60731147946434\n",
      "Train score: 0.3930308007157134\n",
      "Score Improved (0.0 ---> 0.3930308007157134)\n",
      "Epoch: 203\n",
      "Train loss: 105.59397059423007\n",
      "Train score: 0.3938345635943617\n",
      "Score Improved (0.0 ---> 0.3938345635943617)\n",
      "Epoch: 204\n",
      "Train loss: 105.59708464290642\n",
      "Train score: 0.3924922035850462\n",
      "Score Improved (0.0 ---> 0.3924922035850462)\n",
      "Epoch: 205\n",
      "Train loss: 105.56035921654528\n",
      "Train score: 0.39430402222291533\n",
      "Score Improved (0.0 ---> 0.39430402222291533)\n",
      "Epoch: 206\n",
      "Train loss: 105.55787931930637\n",
      "Train score: 0.39421163621228766\n",
      "Score Improved (0.0 ---> 0.39421163621228766)\n",
      "Epoch: 207\n",
      "Train loss: 105.51786254899547\n",
      "Train score: 0.3941913622605235\n",
      "Score Improved (0.0 ---> 0.3941913622605235)\n",
      "Epoch: 208\n",
      "Train loss: 105.50190249625508\n",
      "Train score: 0.3950545437292591\n",
      "Score Improved (0.0 ---> 0.3950545437292591)\n",
      "Epoch: 209\n",
      "Train loss: 105.47147239179922\n",
      "Train score: 0.39746345577130976\n",
      "Score Improved (0.0 ---> 0.39746345577130976)\n",
      "Epoch: 210\n",
      "Train loss: 105.49843738633625\n",
      "Train score: 0.39565613255458487\n",
      "Score Improved (0.0 ---> 0.39565613255458487)\n",
      "Epoch: 211\n",
      "Train loss: 105.47973381681705\n",
      "Train score: 0.3969169690034478\n",
      "Score Improved (0.0 ---> 0.3969169690034478)\n",
      "Epoch: 212\n",
      "Train loss: 105.39901614810981\n",
      "Train score: 0.39682550519499915\n",
      "Score Improved (0.0 ---> 0.39682550519499915)\n",
      "Epoch: 213\n",
      "Train loss: 105.42773875056069\n",
      "Train score: 0.3978260647426274\n",
      "Score Improved (0.0 ---> 0.3978260647426274)\n",
      "Epoch: 214\n",
      "Train loss: 105.3690069689451\n",
      "Train score: 0.3989136866468725\n",
      "Score Improved (0.0 ---> 0.3989136866468725)\n",
      "Epoch: 215\n",
      "Train loss: 105.40538891368486\n",
      "Train score: 0.39933637168254815\n",
      "Score Improved (0.0 ---> 0.39933637168254815)\n",
      "Epoch: 216\n",
      "Train loss: 105.3681596264388\n",
      "Train score: 0.39993768736510366\n",
      "Score Improved (0.0 ---> 0.39993768736510366)\n",
      "Epoch: 217\n",
      "Train loss: 105.40353518202923\n",
      "Train score: 0.39929916448514563\n",
      "Score Improved (0.0 ---> 0.39929916448514563)\n",
      "Epoch: 218\n",
      "Train loss: 105.36247821157427\n",
      "Train score: 0.40065389807737867\n",
      "Score Improved (0.0 ---> 0.40065389807737867)\n",
      "Epoch: 219\n",
      "Train loss: 105.31922555419318\n",
      "Train score: 0.40015396053540336\n",
      "Score Improved (0.0 ---> 0.40015396053540336)\n",
      "Epoch: 220\n",
      "Train loss: 105.30982211652426\n",
      "Train score: 0.4009008443373327\n",
      "Score Improved (0.0 ---> 0.4009008443373327)\n",
      "Epoch: 221\n",
      "Train loss: 105.26662211369009\n",
      "Train score: 0.40097082497095643\n",
      "Score Improved (0.0 ---> 0.40097082497095643)\n",
      "Epoch: 222\n",
      "Train loss: 105.26305123116191\n",
      "Train score: 0.40212014910852056\n",
      "Score Improved (0.0 ---> 0.40212014910852056)\n",
      "Epoch: 223\n",
      "Train loss: 105.25223491690102\n",
      "Train score: 0.4031104169135545\n",
      "Score Improved (0.0 ---> 0.4031104169135545)\n",
      "Epoch: 224\n",
      "Train loss: 105.21569784796868\n",
      "Train score: 0.4033133872369276\n",
      "Score Improved (0.0 ---> 0.4033133872369276)\n",
      "Epoch: 225\n",
      "Train loss: 105.24360927070482\n",
      "Train score: 0.40189482269513316\n",
      "Score Improved (0.0 ---> 0.40189482269513316)\n",
      "Epoch: 226\n",
      "Train loss: 105.19285037736346\n",
      "Train score: 0.4034492973141697\n",
      "Score Improved (0.0 ---> 0.4034492973141697)\n",
      "Epoch: 227\n",
      "Train loss: 105.22523433443462\n",
      "Train score: 0.40348057661246856\n",
      "Score Improved (0.0 ---> 0.40348057661246856)\n",
      "Epoch: 228\n",
      "Train loss: 105.14259079503186\n",
      "Train score: 0.4049220714544889\n",
      "Score Improved (0.0 ---> 0.4049220714544889)\n",
      "Epoch: 229\n",
      "Train loss: 105.1420665837671\n",
      "Train score: 0.40526902992495445\n",
      "Score Improved (0.0 ---> 0.40526902992495445)\n",
      "Epoch: 230\n",
      "Train loss: 105.15281583148476\n",
      "Train score: 0.40466209426892047\n",
      "Score Improved (0.0 ---> 0.40466209426892047)\n",
      "Epoch: 231\n",
      "Train loss: 105.11130130117174\n",
      "Train score: 0.4056408942008068\n",
      "Score Improved (0.0 ---> 0.4056408942008068)\n",
      "Epoch: 232\n",
      "Train loss: 105.07799419476396\n",
      "Train score: 0.40479060326961025\n",
      "Score Improved (0.0 ---> 0.40479060326961025)\n",
      "Epoch: 233\n",
      "Train loss: 105.0683937970071\n",
      "Train score: 0.4065399065965937\n",
      "Score Improved (0.0 ---> 0.4065399065965937)\n",
      "Epoch: 234\n",
      "Train loss: 105.05257771684032\n",
      "Train score: 0.4081325987512758\n",
      "Score Improved (0.0 ---> 0.4081325987512758)\n",
      "Epoch: 235\n",
      "Train loss: 105.04544923475903\n",
      "Train score: 0.4073333980113676\n",
      "Score Improved (0.0 ---> 0.4073333980113676)\n",
      "Epoch: 236\n",
      "Train loss: 105.05402809388609\n",
      "Train score: 0.40746736051985233\n",
      "Score Improved (0.0 ---> 0.40746736051985233)\n",
      "Epoch: 237\n",
      "Train loss: 105.02859543046418\n",
      "Train score: 0.40762783142833253\n",
      "Score Improved (0.0 ---> 0.40762783142833253)\n",
      "Epoch: 238\n",
      "Train loss: 105.0392116377519\n",
      "Train score: 0.40661189273338544\n",
      "Score Improved (0.0 ---> 0.40661189273338544)\n",
      "Epoch: 239\n",
      "Train loss: 104.98749525705955\n",
      "Train score: 0.4087754804061968\n",
      "Score Improved (0.0 ---> 0.4087754804061968)\n",
      "Epoch: 240\n",
      "Train loss: 104.99040512924459\n",
      "Train score: 0.40873075515258506\n",
      "Score Improved (0.0 ---> 0.40873075515258506)\n",
      "Epoch: 241\n",
      "Train loss: 104.98612055490148\n",
      "Train score: 0.4081353777752026\n",
      "Score Improved (0.0 ---> 0.4081353777752026)\n",
      "Epoch: 242\n",
      "Train loss: 104.94762291093076\n",
      "Train score: 0.4086171315858199\n",
      "Score Improved (0.0 ---> 0.4086171315858199)\n",
      "Epoch: 243\n",
      "Train loss: 104.93807640841058\n",
      "Train score: 0.4097405898108075\n",
      "Score Improved (0.0 ---> 0.4097405898108075)\n",
      "Epoch: 244\n",
      "Train loss: 104.91649951309697\n",
      "Train score: 0.40993640457784497\n",
      "Score Improved (0.0 ---> 0.40993640457784497)\n",
      "Epoch: 245\n",
      "Train loss: 104.90125292100375\n",
      "Train score: 0.4101563004921059\n",
      "Score Improved (0.0 ---> 0.4101563004921059)\n",
      "Epoch: 246\n",
      "Train loss: 104.89772376763683\n",
      "Train score: 0.41177350872572605\n",
      "Score Improved (0.0 ---> 0.41177350872572605)\n",
      "Epoch: 247\n",
      "Train loss: 104.88179127792522\n",
      "Train score: 0.41053709003072286\n",
      "Score Improved (0.0 ---> 0.41053709003072286)\n",
      "Epoch: 248\n",
      "Train loss: 104.86233395687944\n",
      "Train score: 0.41123528576017226\n",
      "Score Improved (0.0 ---> 0.41123528576017226)\n",
      "Epoch: 249\n",
      "Train loss: 104.83947297556402\n",
      "Train score: 0.41201440211988205\n",
      "Score Improved (0.0 ---> 0.41201440211988205)\n",
      "Training complete in 2h 38m 18s\n",
      "Best Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_scores, val_losses, val_scores = run_folds(folds=CONFIG['seeds'],\n",
    "                                                               data=\"all\",\n",
    "                                                               save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da33824d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T10:56:10.102032Z",
     "iopub.status.busy": "2023-07-04T10:56:10.101659Z",
     "iopub.status.idle": "2023-07-04T10:56:10.107347Z",
     "shell.execute_reply": "2023-07-04T10:56:10.106461Z"
    },
    "papermill": {
     "duration": 0.09742,
     "end_time": "2023-07-04T10:56:10.110326",
     "exception": false,
     "start_time": "2023-07-04T10:56:10.012906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144.75735007886075, 133.7402452596229, 130.02964778145125, 128.24593204476676, 127.14104035977962, 126.23439418992838, 125.518553835451, 124.84073857372239, 124.21396774708845, 123.62086684472894, 123.01945785439433, 122.44435828107164, 121.92723484837667, 121.43268219595284, 120.93314523647153, 120.4439325264659, 120.04736696169833, 119.60218156106295, 119.18148730059063, 118.7392321317454, 118.44408021746156, 118.05948575733734, 117.75104442241532, 117.45156485033795, 117.1337077625657, 116.82746088331986, 116.55933358125789, 116.27580536014393, 116.03768067422745, 115.77704047344164, 115.51804789545069, 115.33368515197652, 115.1967227409576, 114.89551888817152, 114.7399267894959, 114.5418406655556, 114.34201997903624, 114.18823682339513, 114.00048096411967, 113.8205800366268, 113.71377376160945, 113.51004548807148, 113.3891170405112, 113.24273215067906, 113.08265991519876, 112.93665909414834, 112.80242168406723, 112.69906844975849, 112.50710115354566, 112.411410951843, 112.32434377743634, 112.20930866851663, 112.06263036574911, 111.95481296763127, 111.87833422358634, 111.7630213834876, 111.6613257523069, 111.53997139524238, 111.43986712759418, 111.33741987517031, 111.27311022629638, 111.17305541492736, 111.06384270875343, 110.96620018872439, 110.92122311826287, 110.82627605646712, 110.73528928987211, 110.63899337401476, 110.5438975383284, 110.48863904921976, 110.41011679947712, 110.33183319661188, 110.28180078096938, 110.15638157307775, 110.0957915216239, 110.02946847249741, 109.97629256459193, 109.91992181256862, 109.8379345187712, 109.7870778757902, 109.72423920825099, 109.68248127554804, 109.59976838002207, 109.52240026717047, 109.41601976574573, 109.40006772589165, 109.35614272333054, 109.29262186758427, 109.21461034971917, 109.1638262634891, 109.10320088498754, 109.09170472659295, 109.03361241981699, 108.97809586917104, 108.900159500354, 108.87837900695119, 108.79583509442053, 108.74069072366768, 108.66001174343421, 108.61865606946645, 108.61820896729498, 108.58803272205748, 108.53864865723875, 108.47355374969044, 108.42095369335476, 108.38884041561208, 108.33373651659656, 108.27233869351667, 108.27756067247064, 108.20900265720603, 108.16070159815136, 108.10591503369812, 108.10531188073212, 108.0287638878344, 108.00628656810215, 107.94901255500106, 107.922241848982, 107.89269160616946, 107.82139047220657, 107.78910649138729, 107.80309956375761, 107.71385056659106, 107.70851741964711, 107.63403170455715, 107.62167206149522, 107.57797622997111, 107.57131717958052, 107.50123156189572, 107.4777780100564, 107.44365970033438, 107.38888555758196, 107.39995497094297, 107.3763915763325, 107.34032193914102, 107.29105240127114, 107.21433698530466, 107.22013046794349, 107.23573027816563, 107.13712026996376, 107.14698567426713, 107.12859036047765, 107.11544410573946, 106.99601416242352, 107.0058660411061, 106.99239404437871, 106.94391746516169, 106.91263652000364, 106.8663432423766, 106.85683140214928, 106.83388616924651, 106.80093246279102, 106.79896202606055, 106.73639185940199, 106.71385408055569, 106.71906311068196, 106.67794047163196, 106.6262008908136, 106.58016890667454, 106.587134939924, 106.53506818773803, 106.5247456675689, 106.50450476352006, 106.51929894741744, 106.44287405205382, 106.41631089703914, 106.40869123064832, 106.41423799699196, 106.35374511216295, 106.32300166371196, 106.34457266859194, 106.31550813961901, 106.3060581007806, 106.24610711621693, 106.19150254837804, 106.1594902723925, 106.2029152897492, 106.15652291462962, 106.10431477573094, 106.05969574992392, 106.04537337643893, 106.07562143783234, 105.99564501828348, 106.03780228574433, 105.98423967009737, 105.95565409306548, 105.94047518217505, 105.91837559400956, 105.91347430417862, 105.91014505086022, 105.88285359261856, 105.84799807354243, 105.820230563523, 105.82258504243212, 105.80219598365758, 105.7674945417074, 105.78348796316658, 105.73009774107088, 105.70901396329442, 105.68065050587806, 105.6537336523775, 105.65640570216564, 105.59554241276909, 105.60731147946434, 105.59397059423007, 105.59708464290642, 105.56035921654528, 105.55787931930637, 105.51786254899547, 105.50190249625508, 105.47147239179922, 105.49843738633625, 105.47973381681705, 105.39901614810981, 105.42773875056069, 105.3690069689451, 105.40538891368486, 105.3681596264388, 105.40353518202923, 105.36247821157427, 105.31922555419318, 105.30982211652426, 105.26662211369009, 105.26305123116191, 105.25223491690102, 105.21569784796868, 105.24360927070482, 105.19285037736346, 105.22523433443462, 105.14259079503186, 105.1420665837671, 105.15281583148476, 105.11130130117174, 105.07799419476396, 105.0683937970071, 105.05257771684032, 105.04544923475903, 105.05402809388609, 105.02859543046418, 105.0392116377519, 104.98749525705955, 104.99040512924459, 104.98612055490148, 104.94762291093076, 104.93807640841058, 104.91649951309697, 104.90125292100375, 104.89772376763683, 104.88179127792522, 104.86233395687944, 104.83947297556402]\n"
     ]
    }
   ],
   "source": [
    "print(train_losses[0])\n",
    "if val_losses[0] is not None:\n",
    "    print(val_losses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b74cebdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T10:56:10.275439Z",
     "iopub.status.busy": "2023-07-04T10:56:10.275059Z",
     "iopub.status.idle": "2023-07-04T10:56:10.540273Z",
     "shell.execute_reply": "2023-07-04T10:56:10.539361Z"
    },
    "papermill": {
     "duration": 0.349813,
     "end_time": "2023-07-04T10:56:10.542406",
     "exception": false,
     "start_time": "2023-07-04T10:56:10.192593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses[0])\n",
    "if val_losses[0] is not None:\n",
    "    plt.plot(val_losses[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce74a62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T10:56:10.709466Z",
     "iopub.status.busy": "2023-07-04T10:56:10.709123Z",
     "iopub.status.idle": "2023-07-04T10:56:10.944678Z",
     "shell.execute_reply": "2023-07-04T10:56:10.943024Z"
    },
    "papermill": {
     "duration": 0.322989,
     "end_time": "2023-07-04T10:56:10.947453",
     "exception": false,
     "start_time": "2023-07-04T10:56:10.624464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_scores[0])\n",
    "if val_scores[0] is not None:\n",
    "    plt.plot(val_scores[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2884805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-04T10:56:11.117826Z",
     "iopub.status.busy": "2023-07-04T10:56:11.117466Z",
     "iopub.status.idle": "2023-07-04T10:56:11.137451Z",
     "shell.execute_reply": "2023-07-04T10:56:11.136514Z"
    },
    "papermill": {
     "duration": 0.108482,
     "end_time": "2023-07-04T10:56:11.140055",
     "exception": false,
     "start_time": "2023-07-04T10:56:11.031573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.remove(\"/kaggle/working/train_targets_top\"+str(CONFIG[\"n_labels\"])+\".npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9690.22283,
   "end_time": "2023-07-04T10:56:14.490653",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-04T08:14:44.267823",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
